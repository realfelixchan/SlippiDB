{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Requires nodeenv to run node programs within the venv\n",
    "import os\n",
    "import subprocess\n",
    "import io\n",
    "import json\n",
    "from contextlib import redirect_stdout\n",
    "import glob\n",
    "import slippi\n",
    "from slippi.parse import ParseEvent, ParseError\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyparsing as parse\n",
    "import datetime\n",
    "import duckdb\n",
    "import boto3\n",
    "import psycopg2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a dictionary of parseEvents and handlers and game file destination and returns a Dictionary of strings\n",
    "# Dependencies: parseDict, io, contextlib, slippi.parse\n",
    "# Input: Slippi File path, dictionary of event handlers from slippi.parse\n",
    "# Output: Dictionary {fileName, fileMetadata}\n",
    "def parseFile(slippiFile, parseDict):\n",
    "    parsedDict = {}\n",
    "    parseDict['gameID'] = str(slippiFile)\n",
    "    with io.StringIO() as buffer, redirect_stdout(buffer): \n",
    "        for key in parseDict:\n",
    "            slippi.parse(slippiFile, {key:print})\n",
    "            parsedDict[str(key).lower().replace('parseevent.', '')] = buffer.getvalue()\n",
    "    return parsedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate for slippi files\n",
    "# Dependencies: glob\n",
    "# Input: Directory path\n",
    "# Output: glob iterator to track each .slp file\n",
    "def getSlippiFiles(baseDir):\n",
    "    return glob.glob(baseDir+\"/**/*.slp\", recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the metadata for the JS package\n",
    "def getJSMetadata(slippiFile):\n",
    "    jsMetadataDict = {}\n",
    "    try:\n",
    "        output=subprocess.check_output(r'node .\\slippiStats.js '+slippiFile, shell=True) \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        raise RuntimeError(\"command '{}' return with error (code {}): {}\".format(e.cmd, e.returncode, e.output))\n",
    "        # This has to do with the way the JS library parses the data, will just skip \n",
    "    jsMetadataDict[str(slippiFile)] = str(output).lstrip('b')\n",
    "    return jsMetadataDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes any data as a list and splits it evenly between odd indices and even indices\n",
    "# Created function because of how data needs to be split with the way it's parsed\n",
    "# Input: A list\n",
    "# Output: The inputted list split into two lists\n",
    "def splitList(dataAsList):\n",
    "    playerOneList = dataAsList[0::2]\n",
    "    playerTwoList = dataAsList[1::2]\n",
    "    return playerOneList, playerTwoList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes the JSmetadata information as a String and return player names, both Player 1 and Player 2 from String value, as two separaate Lists\n",
    "# Dependencies: re, splitList\n",
    "# Input: Metadata String from getJSMetadata\n",
    "# Output: Two lists that track the player names for each player per game file\n",
    "def getPlayerNames(metadataString):\n",
    "    playerNames = re.findall(\"displayName: (.*?),\", metadataString)\n",
    "    playerNames = [name.strip(r'\\\\\\'') for name in playerNames]\n",
    "    playerOneList, playerTwoList = splitList(playerNames)\n",
    "    return playerOneList, playerTwoList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes the metadata information as a String and return character names, both Plyaer 1 and Player 2, as two separate lists\n",
    "# Dependencies: re, splitList\n",
    "# Input: Metadata String from getJSMetadata\n",
    "# Output: Two lists that track the character ID for each player per game file\n",
    "def getcharIds(metadataString):\n",
    "    charIds = re.findall(r'(?:characterId: )(\\d+)', metadataString)\n",
    "    playerOneList, playerTwoList = splitList(charIds)\n",
    "    return playerOneList, playerTwoList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes metadata information as a String and returns the stocks taken by each player as two separate lists\n",
    "# Dependencies: pyparsing, splitList\n",
    "# Input: Metadata String that is created from getJSMetadata\n",
    "# Output: Two lists that track stocks taken for each character per game file\n",
    "def getStocksTaken(metadataString):\n",
    "    stocksTaken = []\n",
    "    killCount = parse.Literal('killCount:').suppress() + parse.Word(parse.nums)\n",
    "    for match in killCount.scanString(metadataString):\n",
    "        stocksTaken.append(match[0][0])\n",
    "    playerOneList, playerTwoList = splitList(stocksTaken)\n",
    "    return playerOneList, playerTwoList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a directory path that contains all Slippi files to analyze and place into a dictionary\n",
    "# Dependencies: parseData, slippi.parse\n",
    "# Input: Directory path\n",
    "# Output: Dictionary {fileName, fileMetadata}\n",
    "def parsedData(slippiFile):\n",
    "    handlers = {ParseEvent.FRAME: print, ParseEvent.METADATA: print}\n",
    "    # Dicts where the key is the name of the file, and the value is the string value output\n",
    "    metadataDict = {}\n",
    "    # Came across an issue with the raw data in some select files\n",
    "    try:\n",
    "        parseData = parseFile(slippiFile, handlers)\n",
    "    except (ValueError, ParseError) as error:\n",
    "        print('The file has an issue with its raw data, moving on.')\n",
    "        # This is an issue with the way the data is parsed by the Python library\n",
    "        return\n",
    "    metadataDict[str(slippiFile)] = parseData['metadata']\n",
    "    return metadataDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only processes files that haven't been previously inserted into the database.\n",
    "# This is done by having duckDB's database file to insert into, as well as a log file for checking time stamp\n",
    "# Input: Directory path\n",
    "# Output: via processSlippiFiles, a CSV\n",
    "def processNewFiles(slippiPath):\n",
    "# Get the last processed timestamp from the log file\n",
    "    os.chdir(slippiPath)\n",
    "    slippiFiles = getSlippiFiles(slippiPath)\n",
    "    print(slippiFiles)\n",
    "    try:\n",
    "        with open(logFile, 'r') as f:\n",
    "            lastProcessed = float(f.read())\n",
    "    except FileNotFoundError:\n",
    "        lastProcessed = 0\n",
    "    newFiles = [f for f in slippiFiles if os.path.isfile(f) and os.path.getmtime(f) > lastProcessed]\n",
    "    newFiles.sort()\n",
    "    processSlippiFiles(newFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a directory and parses through the raw data of each file. The purpose is to create CSV files for\n",
    "# uploading to AWS tables\n",
    "# Dependent on the above parsing functions, re, pandas, duckDB, processNewFiles\n",
    "# Input: File directory of .slp files\n",
    "# Output: Main CSV\n",
    "def processSlippiFiles(slippiPath):\n",
    "    conn = duckdb.connect(database='playerDB.db', read_only=False)\n",
    "    conn.execute(\"\"\"CREATE TABLE IF NOT EXISTS gamedata (GameID varchar(25), \n",
    "    PlayerOneName varchar(16),\n",
    "    PlayerTwoName varchar(16),\n",
    "    PlayerOneCharacterID integer,\n",
    "    PlayerTwoCharacterID integer,\n",
    "    PlayerOneStocksTaken integer, \n",
    "    PlayerTwoStocksTaken integer, \n",
    "    StageID integer,\n",
    "    GameDate varchar(30), \n",
    "    GameLength varchar(6))\"\"\")\n",
    "    \n",
    "    for file in slippiPath:\n",
    "        # Data parsing\n",
    "        metadataDict = parsedData(file)\n",
    "        jsMetadataDict = getJSMetadata(file)\n",
    "        playerOneNames, playerTwoNames = getPlayerNames(str(jsMetadataDict.values()))\n",
    "        playerOneChars, playerTwoChars = getcharIds(str(jsMetadataDict.values()))\n",
    "        playerOneStocksTaken, playerTwoStocksTaken = getStocksTaken(str(jsMetadataDict.values()))\n",
    "        stageIds = re.findall(r'(?:stageId: )(\\d+)', str(jsMetadataDict.values()))\n",
    "        gameIDs = [i.lstrip(slippiPath) for i in list(jsMetadataDict.keys())]\n",
    "        gameIDs = [i.rstrip('.slp') for i in gameIDs]\n",
    "        gameDates = re.findall(r'(?:startAt: )(\\S*)\\'', str(jsMetadataDict.values()))\n",
    "        gameDates = [i.strip('\\\\') for i in gameDates]\n",
    "        gameDates = [i.lstrip('\\'') for i in gameDates]\n",
    "        gameLengths = re.findall(r'(?:lastFrame: )(\\d+)', str(jsMetadataDict.values()))\n",
    "        \n",
    "        # String is duplicated a second time, so we're only taking every other result\n",
    "        gameLengths = gameLengths[0::2]\n",
    "        gameLengths = [round(int(i)/3600, 3) for i in gameLengths]\n",
    "        \n",
    "        #Loading the data into a temporary dictionary -> temporary dataframe -> Insert to table\n",
    "        gameData = {'GameID': gameIDs, 'PlayerOneName': playerOneNames, 'PlayerTwoName': playerTwoNames,\n",
    "                    'PlayerOneCharacterID': playerOneChars, 'PlayerTwoCharacterID': playerTwoChars,\n",
    "                    'PlayerOneStocksTaken': playerOneStocksTaken, 'PlayerTwoStocksTaken': playerTwoStocksTaken,\n",
    "                    'StageId': stageIds, 'GameDate': gameDates, 'GameLength': gameLengths}\n",
    "\n",
    "        gameDataDF = pd.DataFrame(data=gameData)\n",
    "        with open(logFile, 'w') as f:\n",
    "            f.write(str(time.time()))\n",
    "        conn.execute(\"INSERT INTO GameData SELECT * FROM gameDataDF\")\n",
    "\n",
    "    conn.execute(\"COPY gameData TO 'GameData.csv' (HEADER, DELIMITER ',')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating derivative CSVs for other tables\n",
    "# Dependencies: Pandas, numpy \n",
    "# Input: CSV created by processSLippiFiles, string of player name\n",
    "# Output: Two CSVs\n",
    "def createOtherCSVs(name = '2Chans'):\n",
    "    gameDataDF=pd.read_csv('.\\GameData.csv')\n",
    "    conditions = [\n",
    "        (gameDataDF['PlayerOneStocksTaken'] == '4') | (gameDataDF['PlayerOneStocksTaken'] > gameDataDF['PlayerTwoStocksTaken']),\n",
    "        (gameDataDF['PlayerTwoStocksTaken'] == '4') | (gameDataDF['PlayerOneStocksTaken'] < gameDataDF['PlayerTwoStocksTaken']),\n",
    "        (gameDataDF['PlayerOneStocksTaken'] == gameDataDF['PlayerTwoStocksTaken'])]\n",
    "    choices = ['1', '2', '0']\n",
    "    gameDataDF['Winner'] = np.select(conditions, choices, default='0')\n",
    "\n",
    "    selfPlayerOne=gameDataDF.loc[gameDataDF['PlayerOneName'] == name][['PlayerOneCharacterID', 'PlayerTwoCharacterID', 'StageID', 'Winner']]\n",
    "    # Flipping the order of the character IDs to make later concatenation more intuitive\n",
    "    selfPlayerTwo=gameDataDF.loc[gameDataDF['PlayerTwoName'] == name][['PlayerTwoCharacterID', 'PlayerOneCharacterID', 'StageID', 'Winner']]\n",
    "    \n",
    "    # Changing column names and winner values to be more consistent\n",
    "    selfPlayerOne.rename(columns={'PlayerOneCharacterID':'SelfCharacterID',\n",
    "                                 'PlayerTwoCharacterID':'OtherCharacterID'}, inplace=True)\n",
    "    conditions = [\n",
    "        (selfPlayerOne['Winner']=='1'),\n",
    "        (selfPlayerOne['Winner']=='2'),\n",
    "        (selfPlayerOne['Winner']=='0')\n",
    "    ]\n",
    "    choices = ['Self', 'Other', 'None']\n",
    "    selfPlayerOne['Winner'] = np.select(conditions, choices, default='None')\n",
    "\n",
    "    selfPlayerTwo.rename(columns={'PlayerTwoCharacterID':'SelfCharacterID',\n",
    "                                 'PlayerOneCharacterID':'OtherCharacterID'}, inplace=True)\n",
    "\n",
    "    conditions = [\n",
    "        (selfPlayerTwo['Winner']=='2'),\n",
    "        (selfPlayerTwo['Winner']=='1'),\n",
    "        (selfPlayerTwo['Winner']=='0')\n",
    "    ]\n",
    "    choices = ['Self', 'Other', 'None']\n",
    "    selfPlayerTwo['Winner'] = np.select(conditions, choices, default='None')\n",
    "\n",
    "    # Group matchup data by characters played and faced, return a win percentage (not including draws/unknown)\n",
    "    matchupResults=pd.concat([selfPlayerOne,selfPlayerTwo]).groupby(['SelfCharacterID', 'OtherCharacterID'])['Winner']\\\n",
    "               .apply(lambda x: 100*((x == 'Self').sum() / (x.isin(['Self', 'Other']).sum()) or np.nan))\\\n",
    "               .reset_index(name='Percentage')\n",
    "\n",
    "    stageResults=pd.concat([selfPlayerOne,selfPlayerTwo]).groupby(['StageID'])['Winner']\\\n",
    "               .apply(lambda x: 100*((x == 'Self').sum() / (x.isin(['Self', 'Other']).sum()) or np.nan))\\\n",
    "               .reset_index(name='Percentage')\n",
    "\n",
    "    ## Matchup table csv\n",
    "    matchupResults.to_csv('MatchupResults.csv')\n",
    "    ## Stage table csv\n",
    "    stageResults.to_csv('StageResults.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to process CSV and upload to RDS\n",
    "# Depndencies: boto3, psycopg2, createOtherCSVs, processNewFiles\n",
    "# Input: String of CSV path, String of destination table\n",
    "# Output: Table insert/update in RDS\n",
    "def upload_to_rds(csvPath, tableName):\n",
    "   # create an STS client and get temporary credentials for the IAM role\n",
    "    sts = boto3.client('sts')\n",
    "    response = sts.assume_role(\n",
    "        RoleArn=roleARN,\n",
    "        RoleSessionName='slippi'\n",
    "    )\n",
    "    credentials = response['Credentials']\n",
    "\n",
    "    # create a connection to the RDS instance using psycopg2\n",
    "    conn = psycopg2.connect(\n",
    "        host='slippi-database.cdkpriuzfx7h.us-east-1.rds.amazonaws.com',\n",
    "        port=5432,\n",
    "        dbname='slippi-database',\n",
    "        user= rdsUsername,\n",
    "        password= rdsPassword,\n",
    "        sslmode='require'\n",
    "    )\n",
    "\n",
    "    # create a cursor and execute the COPY command to upload the CSV data\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"\"\"\n",
    "        COPY '{}'\n",
    "        FROM STDIN\n",
    "        IAM_ROLE '{}'\n",
    "        CSV HEADER;\n",
    "    \"\"\".format(tableName, os.environ['IAM_ROLE_ARN']))\n",
    "\n",
    "    # open the CSV file and copy its contents to the database\n",
    "    with open(csvPath, 'r') as f:\n",
    "        cur.copy_expert(sql=f\"CSV\", file=f)\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "    # close the cursor and connection\n",
    "    cur.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slippiPath = r\"C:\\Users\\pleasework\\Documents\\Slippi\\SlippiAnalysisFiles\"\n",
    "logFile = \".\\logFile.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roleARN = os.environ.get('slippiRoleARN')\n",
    "rdsUsername = os.environ['slippiRDSUsername']\n",
    "rdsPassword = os.environ['slippiRDSPassword']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processNewFiles(slippiPath)\n",
    "createOtherCSVs('2Chans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_to_rds('.\\GameData.csv', 'gamedata')\n",
    "upload_to_rds('.\\MatchupResults.csv', 'matchupresults')\n",
    "upload_to_rds('.\\StageResults.csv', 'stageresults')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
